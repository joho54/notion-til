# [MVP] ì›Œë“œ ì„ë² ë”© ê¸°ë°˜ ë©”ëª¨ì•±



> ê°œë…ê³¼ ì´ìŠˆ íŠ¸ë˜í‚¹ì„ ì¡°í•©í•´ì„œ â€œë³µê¸° ê°€ëŠ¥í•œâ€ ìë£Œë¥¼ ë§Œë“¤ë„ë¡ í•©ë‹ˆë‹¤.

> ì´ìŠˆ íŠ¸ë˜í‚¹ ì‘ì„± ì›ì¹™: Phase1(í™˜ê²½, ë¡œê·¸, ìµœê·¼ ë³€ê²½ì‚¬í•­), Phase2(í™•ì¸, ì‹œë„, ê²°ê³¼ë¶„ì„) í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”. (Phase2ëŠ” ìµœëŒ€ 3íšŒê¹Œì§€ ë°˜ë³µí•˜ê³  í•´ê²° ì•ˆ ë˜ë©´ ì•„ì˜ˆ ì²˜ìŒë¶€í„° ì‹œì‘(ë¶ˆê°€ëŠ¥í•  ê²½ìš° ë„ì›€ ìš”ì²­))

> ì‹¤ìŠµì€ ì²œì²œíˆ, í•˜ì§€ë§Œ robustí•˜ê²Œ í•˜ì„¸ìš”. 

> MVP, ì´ìŠˆ ì´ ë‘ê°€ì§€ë§Œ ìˆìœ¼ë©´ í”„ë¡œì íŠ¸ëŠ” ëšë”±ì´ë‹¤.



# Quick Demo

```python
from sentence_transformers import SentenceTransformer

# SBERT ëª¨ë¸ ë¡œë“œ
model = SentenceTransformer("all-MiniLM-L6-v2")

# ì˜ˆì œ ë©”ëª¨
memos = [
    "Python is a great programming language.",
    "Machine learning is powerful.",
    "Deep learning is a subset of machine learning.",
    "I love coding in Python.",
    "So if i buy some snacks here, it could be a disaster for both of us.",
    "The people without the knowledge of hebrew made christianity worse",
    "The bible is written of hebrew, not the language you use.",
]

# ë²¡í„° ë³€í™˜
vectors = model.encode(memos)
print(vectors.shape)  # (4, 384)  -> 4ê°œ ë¬¸ì„œ, 384ì°¨ì› ë²¡í„°

#### search test

import faiss
import numpy as np

# ë²¡í„° ì°¨ì› ì„¤ì •
dim = vectors.shape[1]

# FAISS ì¸ë±ìŠ¤ ìƒì„±
index = faiss.IndexFlatL2(dim)  # L2 ê±°ë¦¬ ê¸°ë°˜ ê²€ìƒ‰
index.add(np.array(vectors))  # ë²¡í„° ì¶”ê°€

# ê²€ìƒ‰ ì˜ˆì œ (ì²« ë²ˆì§¸ ë¬¸ì„œì™€ ê°€ì¥ ê°€ê¹Œìš´ ë©”ëª¨ ì°¾ê¸°)
D, I = index.search(np.array([vectors[0]]), k=2)  # k=2 (ìê¸° ìì‹  í¬í•¨)
print("closest document with the first document:", I)  # ê°€ì¥ ê°€ê¹Œìš´ ë¬¸ì„œ ì¸ë±ìŠ¤ ì¶œë ¥

#### dimension reduction
import umap

# UMAPìœ¼ë¡œ 2Dë¡œ ì¶•ì†Œ
umap_model = umap.UMAP(n_components=2, random_state=42)
vectors_2d = umap_model.fit_transform(vectors)

print(vectors_2d)  # 2ì°¨ì› ì¢Œí‘œê°’ ì¶œë ¥

### visualization
import networkx as nx
import matplotlib.pyplot as plt

# ê·¸ë˜í”„ ìƒì„±
G = nx.Graph()

# ë…¸ë“œ ì¶”ê°€
for i, (x, y) in enumerate(vectors_2d):
    G.add_node(i, pos=(x, y), label=memos[i])

# ê±°ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ê°„ì„  ì¶”ê°€
threshold = 1.5  # ê±°ë¦¬ ì„ê³„ê°’ ì„¤ì •
for i in range(len(vectors_2d)):
    for j in range(i + 1, len(vectors_2d)):
        dist = np.linalg.norm(vectors_2d[i] - vectors_2d[j])
        if dist < threshold:
            G.add_edge(i, j, weight=dist)

# ë…¸ë“œ ìœ„ì¹˜ ì„¤ì •
pos = nx.get_node_attributes(G, "pos")

# ê·¸ë˜í”„ ì‹œê°í™”
plt.figure(figsize=(8, 6))
nx.draw(
    G,
    pos,
    with_labels=True,
    labels=nx.get_node_attributes(G, "label"),
    node_size=3000,
    font_size=10,
    edge_color="gray",
)
plt.show()

```

# Q. SBERTê°€ í† í¬ë‚˜ì´ì§•ê³¼ ì„ë² ë”©ì„ ê°™ì´ í•´ ì£¼ëŠ” ê±´ê°€?

A. 

ë„¤, SBERT (Sentence-BERT) ëŠ” í† í¬ë‚˜ì´ì§•(tokenization)ê³¼ ì„ë² ë”©(embedding) ì„ ë™ì‹œì— ìˆ˜í–‰í•©ë‹ˆë‹¤. ì¦‰, í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ í† í°í™”í•œ í›„ ì„ë² ë”© ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

âœ… SBERTì˜ ë‚´ë¶€ ì²˜ë¦¬ ê³¼ì •

SBERT ëª¨ë¸ì„ ì‚¬ìš©í•  ë•Œ, model.encode(text) í•¨ìˆ˜ê°€ ë‚´ë¶€ì ìœ¼ë¡œ í•˜ëŠ” ì‘ì—…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

1.	í† í¬ë‚˜ì´ì§• (Tokenization)

â€¢	ì…ë ¥ëœ ë¬¸ì¥ì„ WordPiece í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ í† í°ìœ¼ë¡œ ë³€í™˜.

â€¢	ì˜ˆì‹œ:

```plain text
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')

text = "I love natural language processing."
tokens = model.tokenizer.tokenize(text)
print(tokens)
```

ì¶œë ¥ ì˜ˆì‹œ:

```plain text
['i', 'love', 'natural', 'language', 'processing', '.']
```

2.	ì…ë ¥ ì¸ë±ìŠ¤ ë³€í™˜ (Token ID ë³€í™˜)

â€¢	í† í°ì„ ì‚¬ì „ì—ì„œ ID (ì •ìˆ˜í˜• ì¸ë±ìŠ¤) ë¡œ ë³€í™˜.

```plain text
input_ids = model.tokenizer.encode(text)
print(input_ids)
```

ì¶œë ¥ ì˜ˆì‹œ:

```plain text
[101, 1045, 2293, 3019, 2653, 6845, 1012, 102]
```

(ì—¬ê¸°ì„œ 101ì€ [CLS], 102ëŠ” [SEP] í† í°)

3.	SBERT ëª¨ë¸ì„ í†µí•´ ì„ë² ë”© ë²¡í„° ìƒì„±

â€¢	Transformer ê¸°ë°˜ ëª¨ë¸(BERT, MiniLM ë“±)ì„ ì‚¬ìš©í•´ í† í°ì„ ë²¡í„°ë¡œ ë³€í™˜.

â€¢	[CLS] í† í°ì˜ ë²¡í„°ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, ì „ì²´ í† í°ì˜ í‰ê·  í’€ë§ì„ ì ìš©í•˜ì—¬ ë¬¸ì¥ ë²¡í„° ìƒì„±.

```plain text
embedding = model.encode(text)
print(embedding.shape)  # (384,)  -> 384ì°¨ì› ë²¡í„° ì¶œë ¥
```

ğŸš€ ê²°ë¡ 

âœ… SBERTëŠ” í† í¬ë‚˜ì´ì§•ê³¼ ì„ë² ë”©ì„ ìë™ìœ¼ë¡œ ìˆ˜í–‰

âœ… ì‚¬ìš©ìê°€ ë”°ë¡œ í† í°í™”í•  í•„ìš” ì—†ì´ model.encode(text) í˜¸ì¶œë§Œ í•˜ë©´ ë¨

âœ… ë‚´ë¶€ì ìœ¼ë¡œ WordPiece í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ BERT ìŠ¤íƒ€ì¼ì˜ ì…ë ¥ì„ ë§Œë“¦

âœ… ìµœì¢…ì ìœ¼ë¡œ 384ì°¨ì› ë˜ëŠ” 768ì°¨ì› ë²¡í„°ë¥¼ ë°˜í™˜ (ëª¨ë¸ ì¢…ë¥˜ì— ë”°ë¼ ë‹¤ë¦„)

í˜¹ì‹œ ë” ê¶ê¸ˆí•œ ì  ìˆìœ¼ë©´ ì•Œë ¤ì£¼ì„¸ìš”! ğŸ˜Š



# Q. D3.jsê°€ ë­ì§€?

# MVP í›„ë³´

1. í•œ ë©”ëª¨ ë¬¸ì„œë¥¼ ë‹¤ì°¨ì› ë²¡í„°ë¡œ ì„ë² ë”©í•´ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ì•± í”„ë¡œì íŠ¸ êµ¬ì¶•
1. ì„ë² ë”©ëœ ë‹¤ì°¨ì› ë²¡í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í™”ë©´ ìƒì— x, y ê°’ì„ ê°€ì§€ëŠ” ë…¸ë“œë¡œ ë©”ëª¨ë¥¼ í‘œí˜„
1. ê° ë©”ëª¨ ë¬¸ì„œì˜ ë²¡í„° ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì„œë¡œê°„ì˜ ê±°ë¦¬ë¥¼ ê²°ì •í•˜ì—¬ ë…¸ë“œë¥¼ ë°°ì¹˜. ì´ë•Œ ëª¨ë“  ë©”ëª¨ ë…¸ë“œ ì¤‘ í•˜ë‚˜ë¥¼ ê¸°ì¤€ì ìœ¼ë¡œ ì‚¼ëŠ”ë‹¤.
1. ì´ì œ ë¹ ë¥´ê²Œ UI ì…í˜€ ë³´ê³  í›„ì† ì‘ì—…ìœ¼ë¡œ ë„˜ì–´ê°ˆ ê²ƒ
  1. ë©”ëª¨ ì¶”ê°€ ë²„íŠ¼ì„ ìƒì„±í•˜ì.
  1. ë©”ëª¨ ì¢Œí‘œ ë¡œì§ì— ì„ë² ë”©ê¸°ë°˜ ì¢Œí‘œ ì—…ë°ì´íŠ¸ ë¡œì§ì„ ì¶”ê°€ â†’ vector2coord.py ëª¨ë“ˆì„ ë§Œë“¤ì–´ì„œ í•´ê²°.
  1. ì´ ëª¨ë“ˆì˜ ì‚¬ìš© ë°©ë²•. ë©”ëª¨ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥ â†’ ê° ë©”ëª¨ì˜ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¦¬í„´
  1. argument: [{â€textâ€: â€œmemo contentsâ€, â€œxâ€: 1.2, â€œyâ€: -0.5}, {â€textâ€: â€œmemo contentsâ€, â€œxâ€: 1.2, â€œyâ€: -0.5}â€¦.]
  1. return: fix initial values using logis
1. DBMS ì—°ë™ ì•„ë‹ˆì•„ë‹ˆ


# ì´ìŠˆ: faiss ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì•ˆ ë¨

## Phase1.

í™˜ê²½: macOS, m1, python 3.10.7, 

ë¡œê·¸

î‚° pip install faiss
ERROR: Could not find a version that satisfies the requirement faiss (from versions: none)
ERROR: No matching distribution found for faiss

ìµœê·¼ë³€ê²½ì‚¬í•­: ê°œë°œ í™˜ê²½ êµ¬ì¶• ì¤‘. 

## Phase2-1: í•´ê²°(GPTì˜ ì˜ëª»ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª… ì¶”ì²œì´ ë¬¸ì œì˜€ìŒ)

í™•ì¸: pip install faissëŠ” PyPIì—ì„œ ê³µì‹ ì§€ì› ì•ˆ ë˜ê³  ëŒ€ì‹  faiss-cpu í˜¹ì€ faiss-gpuë¥¼ ì¨ì•¼ í•¨.

ì‹œë„: pip install faiss-cpu

ê²°ê³¼ ë¶„ì„: ì„±ê³µ

# ì´ìŠˆ: UMAP ì‘ë™ ì•ˆ í•¨

## Phase1.

í™˜ê²½: macOS, m1, python 3.10.7

ë¡œê·¸

Exception has occurred: AttributeError

module 'umap' has no attribute 'UMAP'

File "/Users/johyeonho/memo-embedding/main.py", line 38, in <module>
    umap_model = umap.UMAP(n_components=2, random_state=42)
AttributeError: module 'umap' has no attribute 'UMAP'

ìµœê·¼ ë³€ê²… ì‚¬í•­: umap_model = umap.UMAP(n_components=2, random_state=42) ì‹¤í–‰

## Phase2-1

í™•ì¸: umapì´ ì•„ë‹ˆë¼ umap-learnì´ ì˜¬ë°”ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì´ë¦„.

ì‹œë„: umap ì‚­ì œ í›„ pip install umap-learn ì„¤ì¹˜

ê²°ê³¼ ë¶„ì„: ì„±ê³µ


# ì´ìŠˆ: vscode ì½”íŒŒì¼ëŸ¿ í™œì„±í™” ì•ˆ ë¨

## Phase1.

í™˜ê²½: macOS, m1

ë¡œê·¸

ì•„ë¬´ ë¡œê·¸ ì—†ìŒ

ìµœê·¼ë³€ê²½ì‚¬í•­: sign in to github copilot ë²„íŠ¼ í´ë¦­ í›„ ë¬´ë°˜ì‘. 

## Phase2-1

í™•ì¸: VS Codeì—ì„œ GitHub ì¸ì¦ í™•ì¸ ë° ì¬ë¡œê·¸ì¸

ì‹œë„:	GitHub ë¡œê·¸ì•„ì›ƒ í›„ ë‹¤ì‹œ ë¡œê·¸ì¸

ê²°ê³¼ ë¶„ì„: ì•„ë¬´ ë³€í™” ì—†ìŒ.

## Phase2-2

í™•ì¸: í™•ì¥ ì‚­ì œ í›„ ë‹¤ì‹œ ì‹œë„

ì‹œë„: ê·¸ëŒ€ë¡œ

ê²°ê³¼ë¶„ì„: ì•„ë¬´ ë³€í™” ì—†ìŒ

## Phase2-3

í™•ì¸: VS Code ì„¤ì •ì—ì„œ GitHub Enterprise (GHE) ì—°ê²° í™•ì¸

ì‹œë„: Preferences: Open Settings (JSON)ì— ì•„ë˜ ì„¤ì •ì´ ìˆëŠ”ì§€ í™•ì¸

"github.copilot.advancedSettings": {
"serverUrl": "https://github.com"
}

(user) settings.json ì— í•´ë‹¹ ì„¤ì • ì¶”ê°€.

ê²°ê³¼ë¶„ì„: ì•„ë¬´ ë³€í™” ì—†ìŒ

## Phase2-4

í™•ì¸: curl https://api.github.comì„ í†µí•´ ì„œë²„ì™€ í†µì‹  ê°€ëŠ¥í•œì§€ í™•ì¸

ì‹œë„: ê·¸ëŒ€ë¡œ ì‹¤ì‹œ

ê²°ê³¼ ë¶„ì„: json í˜•ì‹ì˜ ì¶œë ¥ì´ ì •ìƒì ìœ¼ë¡œ ëŒì•„ì˜´. ì•„ë¬´ ë³€í™” ì—†ìŒ.

## Phase2-5

í™•ì¸: ì¸ì¦ ìºì‹œ ì‚­ì œ

ì‹œë„: rm -rf ~/.config/github-copilot

ê²°ê³¼ ë¶„ì„: ì•„ë¬´ ë³€í™” ì—†ìŒ

## Phase3. ì¬ì„¤ì¹˜, í•´ê²°



# ì´ìŠˆ: umap_model.fit_transform(vectors) ì‹¤íŒ¨

## Phase1. 

í™˜ê²½: macOS, m1, python 3.10.7

ë¡œê·¸

Exception has occurred: ValueError

zero-size array to reduction operation maximum which has no identity

File "/Users/johyeonho/memo-embedding/vector2coord.py", line 21, in convert
    vectors_2d = umap_model.fit_transform(vectors)
  File "/Users/johyeonho/memo-embedding/vector2coord.py", line 30, in <module>
    memos = Vector2Coord.convert([
ValueError: zero-size array to reduction operation maximum which has no identity
ë³€ê²½ì‚¬í•­

ë¬¸ì œê°€ ë˜ëŠ” ë¶€ë¶„

```python

class Vector2Coord:
    @staticmethod
    def convert(memos):
        if not memos:
            return memos
        
        # Load SBERT model
        model = SentenceTransformer("all-MiniLM-L6-v2")
        
        # Extract texts from memos
        texts = [memo["text"] for memo in memos]
        
        # Convert texts to vectors
        vectors = model.encode(texts)
        
        # Reduce dimensions to 2D using UMAP
        umap_model = umap.UMAP(n_components=2, random_state=42)
        vectors_2d = umap_model.fit_transform(vectors)
        
        # Update memos with new coordinates
        for i, memo in enumerate(memos):
            memo["x"], memo["y"] = vectors_2d[i].tolist()
        
        return memos
```

ì•„ë˜ì˜ ê²½ìš° ì—ëŸ¬ ì—†ìŒ(ìš”ì†Œê°€ í•˜ë‚˜)

```markdown
    memos = Vector2Coord.convert([
        {"text": "Finish AI project", "x": 0.3, "y": -1.2}
    ])
```

ì•„ë˜ì™€ ê°™ì„ ê²½ìš° ì—ëŸ¬ ë°œìƒ

```javascript
    memos = Vector2Coord.convert([
        {"text": "Meeting at 3PM", "x": 1.2, "y": -0.5},
        {"text": "Finish AI project", "x": 0.3, "y": -1.2}
    ])
```

## Phase2-1: í•´ê²°

í™•ì¸: ì½”ë“œ ì‘ë™ë°©ì‹ í™•ì¸

vectors = model.encode(texts) ë™ì‘ì˜ ê²°ê³¼ê°€ ë¬´ì—‡ì¸ê°€?

texts ë¦¬ìŠ¤íŠ¸ì˜ ëª¨ë“  ë¬¸ì¥ì„ í•œ ë²ˆì— ë²¡í„°ë¡œ ë³€í™˜

ì¶œë ¥: vectors.shape = (N, 384) (Nê°œì˜ ë¬¸ì¥, 384ì°¨ì› ë²¡í„°) 

ì¦‰ ì£¼ì–´ì§€ëŠ” textsê°€ ëª‡ê°œë“  ìƒê´€ì´ ì—†ë‹¤.

```python
print(vectors.shape)  # (2, 384)
# ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ ë²¡í„° ì¼ë¶€ ì¶œë ¥
print(vectors[0][:5])  # [ 0.0213 -0.1154  0.3072 -0.0847  0.2913]


```

vectors_2d = umap_model.fit_transform(vectors)ì˜ ë™ì‘ ê²°ê³¼ëŠ” ë¬´ì—‡ì¸ê°€?

ê·¸ëƒ¥ ë³„ê±° ì—†ìŒ

â†’ ì–´ë–¨ê²°ì— í•´ê²°

ì‹œë„: ê·¸ëƒ¥ ì´ˆê¸° ì…ë ¥ ë°ì´í„°ë¥¼ ë§ì´ ì¤¬ìŒ. í•œ 7ê°œ. ê·¸ë¬ë”ë‹ˆ ì‘ë™í•¨. ì„ë² ë”©ì´ ê¸°ë³¸ì ìœ¼ë¡œ ì „ì²´ ë¬¸ì„œì˜ ì§‘í•©ì´ í•„ìš”í•œ ì‘ì—…ì´ë¼ ê·¸ëŸ°ë“¯. AI ì˜ëª»ì€ ì•„ë‹˜.

ê²°ê³¼ë¶„ì„: ì„±ê³µ

â†’ ê·¸ë ‡ë‹¤ë©´ ì´ˆê¸° ì£¼ì–´ì§€ëŠ” ë¬¸ì„œë¥¼ ì–´ë–»ê²Œ ì´ˆê¸°í™”í•´ì•¼ ê· í˜•ìˆê²Œ ë¬¸ì„œë¥¼ ì„ë² ë”©í•  ìˆ˜ ìˆì„ê¹Œ?



